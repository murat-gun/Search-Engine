{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MIH0TjCaijC",
        "outputId": "cdb25293-363e-4c36-e10e-01747667cd9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This graph has 6 elements. These are:\n",
            "\t1.  https://ayaktayolcukalmasin.com.tr/ana_sayfa.html: https://ayaktayolcukalmasin.com.tr/ankara.html, https://ayaktayolcukalmasin.com.tr/konya.html, https://ayaktayolcukalmasin.com.tr/istanbul.html, https://ayaktayolcukalmasin.com.tr/oktayrecommends.html, https://ayaktayolcukalmasin.com.tr/seymarecommends.html\n",
            "\t2.  https://ayaktayolcukalmasin.com.tr/seymarecommends.html: https://ayaktayolcukalmasin.com.tr/oktayrecommends.html, https://ayaktayolcukalmasin.com.tr/konya.html\n",
            "\t3.  https://ayaktayolcukalmasin.com.tr/oktayrecommends.html: https://ayaktayolcukalmasin.com.tr/istanbul.html\n",
            "\t4.  https://ayaktayolcukalmasin.com.tr/istanbul.html: \n",
            "\t5.  https://ayaktayolcukalmasin.com.tr/konya.html: https://ayaktayolcukalmasin.com.tr/seymarecommends.html\n",
            "\t6.  https://ayaktayolcukalmasin.com.tr/ankara.html: \n",
            "The rank of the page https://ayaktayolcukalmasin.com.tr/ana_sayfa.html:  0.033333333333333326\n",
            "The rank of the page https://ayaktayolcukalmasin.com.tr/seymarecommends.html:  0.10274769919999999\n",
            "The rank of the page https://ayaktayolcukalmasin.com.tr/oktayrecommends.html:  0.07998944255999998\n",
            "The rank of the page https://ayaktayolcukalmasin.com.tr/istanbul.html:  0.10274769919999999\n",
            "The rank of the page https://ayaktayolcukalmasin.com.tr/konya.html:  0.07998944255999998\n",
            "The rank of the page https://ayaktayolcukalmasin.com.tr/ankara.html:  0.038666666666666655\n",
            "\t\n",
            "Ranking from more popular to less for the key:\n",
            "https://ayaktayolcukalmasin.com.tr/istanbul.html\n",
            "https://ayaktayolcukalmasin.com.tr/konya.html\n",
            "https://ayaktayolcukalmasin.com.tr/ankara.html\n",
            "https://ayaktayolcukalmasin.com.tr/ana_sayfa.html\n"
          ]
        }
      ],
      "source": [
        "#Murat GÃ¼n Search Engine Project\n",
        "def get_page(url):\n",
        "  try:\n",
        "    import urllib.request\n",
        "    page = urllib.request.urlopen(url).read()\n",
        "    page = page.decode(\"utf-8\")\n",
        "    return page\n",
        "  except:\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "def get_next_target(page):\n",
        "    start_link = page.find('<a href=')\n",
        "    if start_link == -1:\n",
        "        return None, 0\n",
        "    start_quote = page.find('\"', start_link)\n",
        "    end_quote = page.find('\"', start_quote+1)\n",
        "    url = page[start_quote + 1:end_quote]\n",
        "    return url, end_quote\n",
        "\n",
        "\n",
        "def get_all_links(page):\n",
        "    links = []\n",
        "    while True:\n",
        "      url, endpos = get_next_target(page)\n",
        "      if url:\n",
        "        links.append(url)\n",
        "        page = page[endpos:]\n",
        "      else:\n",
        "        break\n",
        "    return links\n",
        "\n",
        "\n",
        "def union(p,q):\n",
        "    for e in q:\n",
        "        if e not in p:\n",
        "            p.append(e)\n",
        "\n",
        "\n",
        "def add_toIndex(index, keyword, url):\n",
        "    if keyword in index:\n",
        "        index[keyword].append(url)\n",
        "    else:\n",
        "        index[keyword] = [url]\n",
        "\n",
        "def getclearpage(content):\n",
        "  title = content[content.find(\"<title>\")+7:content.find(\"</title>\")]\n",
        "  body = content[content.find(\"<body>\")+6:content.find(\"</body>\")]\n",
        "  while body.find(\">\") != -1:\n",
        "    start =  body.find(\"<\")\n",
        "    end =  body.find(\">\")\n",
        "    body = body[:start] + body[end+1:]\n",
        "  return title + body\n",
        "\n",
        "\n",
        "def addPageToIndex(index, url, content):\n",
        "  content = getclearpage(content)\n",
        "  words = content.split()\n",
        "  for word in words:\n",
        "    add_toIndex(index, word, url)\n",
        "\n",
        "def crawlWeb(seed):\n",
        "  tocrawl = [seed]\n",
        "  crawled = []\n",
        "  index = {}\n",
        "  graph = {}\n",
        "  while tocrawl:\n",
        "    page = tocrawl.pop()\n",
        "    if page not in crawled:\n",
        "      content = get_page(page)\n",
        "      addPageToIndex(index, page, content)\n",
        "      outlinks = get_all_links(content)\n",
        "      graph[page] = outlinks\n",
        "      union(tocrawl, get_all_links(get_page(page)))\n",
        "      crawled.append(page)\n",
        "  return index, graph\n",
        "\n",
        "def originallookup(index, keyword):\n",
        "    if keyword in index:\n",
        "        return index[keyword]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def computeRanks(graph):\n",
        "    d =  0.8 # damping factor\n",
        "    N = len(graph)\n",
        "    numloops = 10  # effects the accuracy\n",
        "    ranks = {}\n",
        "    for page in graph:\n",
        "        ranks[page] = 1/N\n",
        "    for i in range(0, numloops):\n",
        "        newranks = {}\n",
        "        for page in graph:\n",
        "            newrank = (1-d)/N\n",
        "            for node in graph:\n",
        "                if page in graph[node]:\n",
        "                    newrank = newrank + d*(ranks[node] / len(graph[node]))\n",
        "            newranks[page] = newrank\n",
        "        ranks = newranks\n",
        "    return newranks\n",
        "\n",
        "\n",
        "\n",
        "# This graph for a given a seed page gives a dictionary in which elements of it are links that are reached from the seed page or\n",
        "# links that are reached from the reached ones. In the graph, value of a link (since it is a dictionary, I use that terminology)\n",
        "# is a list of links that are reached by the given link. \"Reaching\" in that context is having the link in the source code.\n",
        "\n",
        "\n",
        "#1b\n",
        "\n",
        "def urlsAsStrings(list):\n",
        "    string = \"\"\n",
        "    for i in list:\n",
        "        string = string + i + \", \"\n",
        "    finalString = string[:-2]\n",
        "    return finalString\n",
        "\n",
        "seed = \"https://ayaktayolcukalmasin.com.tr/ana_sayfa.html\"\n",
        "index1,graph1 = crawlWeb(seed)\n",
        "print(\"This graph has \" + str(len(graph1)) + \" elements. These are:\")\n",
        "counter = 1\n",
        "for elements in graph1:\n",
        "    String = urlsAsStrings(graph1[elements])\n",
        "    print(\"\\t\" + str(counter) + \".  \" + elements + \": \" + String)\n",
        "    counter = counter + 1\n",
        "\n",
        "\n",
        "#1c\n",
        "\n",
        "def computeRanks(graph):\n",
        "    d =  0.8 # damping factor\n",
        "    N = len(graph)\n",
        "    numloops = 10  # effects the accuracy\n",
        "    ranks = {}\n",
        "    for page in graph:\n",
        "        ranks[page] = 1/N\n",
        "    for i in range(0, numloops):\n",
        "        newranks = {}\n",
        "        for page in graph:\n",
        "            newrank = (1-d)/N\n",
        "            for node in graph:\n",
        "                if page in graph[node]:\n",
        "                    #print(len(graph[node]))\n",
        "                    #print(graph[node])\n",
        "                    newrank = newrank + d*(ranks[node] / len(graph[node]))\n",
        "            newranks[page] = newrank\n",
        "        ranks = newranks\n",
        "    return newranks\n",
        "\n",
        "computeRanks(graph1)\n",
        "for page in graph1:\n",
        "    print(\"The rank of the page \" + page + \":  \" + str(computeRanks(graph1)[page]))\n",
        "\n",
        "#1d\n",
        "\n",
        "def functionForDictOrder(dict):                 #I defined that functions which orders the elements in descending values\n",
        "    newDict = {}                                #f.e {\"link1\":0.2, \"link2\": 0.1, \"link3\":0.4} gets {'link3': 0.4, 'link1': 0.2, 'link2': 0.1}.\n",
        "    for i in dict:\n",
        "        newDict[dict[i]] = i\n",
        "    listofValues = sorted(newDict, reverse=True)\n",
        "    dictOrdered = {}\n",
        "    for i in listofValues:\n",
        "        dictOrdered[newDict[i]] = i\n",
        "    return dictOrdered\n",
        "def rankedLookup(index, keyword , graph):\n",
        "    dict = {}\n",
        "    x = index[keyword]\n",
        "    for i in x:\n",
        "        a,b = i,(computeRanks(graph)[i])\n",
        "        dict[a] = b\n",
        "    return functionForDictOrder(dict)\n",
        "\n",
        "\n",
        "\n",
        "#1e\n",
        "\n",
        "def rankedLookup(index, keyword , graph, rankmethod): #Updated version of rankedLookup where it gets also \"rankmethod\" argument\n",
        "    dict = {}\n",
        "    x = index[keyword]\n",
        "    for i in x:\n",
        "        a,b = i,(rankmethod(graph)[i])\n",
        "        dict[a] = b\n",
        "    return functionForDictOrder(dict)\n",
        "\n",
        "\n",
        "def lookup (index , keyword, graph=None, rankmethod=None):\n",
        "    if graph==None and rankmethod==None:\n",
        "        return originallookup(index, keyword) #I renamed the first version of \"lookup\" into \"originallookup\"\n",
        "    elif graph==None or rankmethod==None:\n",
        "        print(\"This procedure takes 4 inputs these are:\" + \"\\n\\t\" + \"1-An index\" + \"\\n\\t\"\n",
        "              \"2-A key\" + \"\\n\\t\" + \"3-A graph\" + \"\\n\\t\" + \"4-A computing procedure\" + \"\\n\\t\\trespectively.\" +\n",
        "              \"\\nYou have 2 option to use this lookup procedure: with or without keyword.\\n\" +\n",
        "              \"\\t-If you intend to use it without page rank be sure you have given only two inputs, index and key, respectively.\"\n",
        "              + \"\\n\\t-If you intend to use it with page rank be sure you have given all four input in the given order.\" +\n",
        "              \"\\nINVALID INPUT COMBINATION: Please check the inputs.\" )\n",
        "        exit()\n",
        "    else:\n",
        "        return rankedLookup(index, keyword, graph, rankmethod)\n",
        "\n",
        "see = lookup(index1, \"in\", graph1, computeRanks)\n",
        "print(\"\\t\\nRanking from more popular to less for the key:\")\n",
        "for e in see:\n",
        "  print(e)"
      ]
    }
  ]
}